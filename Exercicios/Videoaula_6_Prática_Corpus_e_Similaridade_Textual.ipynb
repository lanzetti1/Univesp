{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanzetti1/Univesp/blob/main/Videoaula_6_Pr%C3%A1tica_Corpus_e_Similaridade_Textual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COM550 - Processamento de Linguagem Natural\n",
        "\n",
        "## Semana 2 - Introdução ao Processamento de Linguagem Natural\n",
        "## Videoaula 6 - *Corpus* e Similaridade Textual\n"
      ],
      "metadata": {
        "id": "MD5gnbZ1QEWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revisão sobre *Corpus*"
      ],
      "metadata": {
        "id": "Hdkb0UKxC_I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poema = \"\"\"E agora, José?\n",
        "A festa acabou,\n",
        "a luz apagou,\n",
        "o povo sumiu,\n",
        "a noite esfriou,\n",
        "e agora, José?\n",
        "e agora, você?\n",
        "você que é sem nome,\n",
        "que zomba dos outros,\n",
        "você que faz versos,\n",
        "que ama, protesta?\n",
        "e agora, José?\n",
        "\n",
        "Está sem mulher,\n",
        "está sem discurso,\n",
        "está sem carinho,\n",
        "já não pode beber,\n",
        "já não pode fumar,\n",
        "cuspir já não pode,\n",
        "a noite esfriou,\n",
        "o dia não veio,\n",
        "o bonde não veio,\n",
        "o riso não veio,\n",
        "não veio a utopia\n",
        "e tudo acabou\n",
        "e tudo fugiu\n",
        "e tudo mofou,\n",
        "e agora, José?\n",
        "\n",
        "E agora, José?\n",
        "Sua doce palavra,\n",
        "seu instante de febre,\n",
        "sua gula e jejum,\n",
        "sua biblioteca,\n",
        "sua lavra de ouro,\n",
        "seu terno de vidro,\n",
        "sua incoerência,\n",
        "seu ódio - e agora?\n",
        "\n",
        "Com a chave na mão\n",
        "quer abrir a porta,\n",
        "não existe porta;\n",
        "quer morrer no mar,\n",
        "mas o mar secou;\n",
        "quer ir para Minas,\n",
        "Minas não há mais.\n",
        "José, e agora?\n",
        "\n",
        "Se você gritasse,\n",
        "se você gemesse,\n",
        "se você tocasse\n",
        "a valsa vienense,\n",
        "se você dormisse,\n",
        "se você cansasse,\n",
        "se você morresse...\n",
        "Mas você não morre,\n",
        "você é duro, José!\n",
        "\n",
        "Sozinho no escuro\n",
        "qual bicho-do-mato,\n",
        "sem teogonia,\n",
        "sem parede nua\n",
        "para se encostar,\n",
        "sem cavalo preto\n",
        "que fuja a galope,\n",
        "você marcha, José!\n",
        "José, para onde?\"\"\"\n"
      ],
      "metadata": {
        "id": "wYkXdvkURMde"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt') # necessário para baixar o tokenizador"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jApV77_rUBgF",
        "outputId": "a1d3e2fc-84fc-4147-ab51-adc41fc49685"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contagem de *tokens* e *types*"
      ],
      "metadata": {
        "id": "1LwpkxXORdtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenize.word_tokenize(poema, language=\"portuguese\")\n",
        "minusculas = tokenize.word_tokenize(poema.lower(), language=\"portuguese\")\n",
        "\n",
        "vocabulario = set(minusculas)\n",
        "\n",
        "print(\"Quantidade de tokens: \",len(tokens))\n",
        "print(\"Quantidade de types: \",len(vocabulario))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbDbLBsORePM",
        "outputId": "092b8348-c74b-4d99-80b5-c2f0ad4ed681"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens:  274\n",
            "Quantidade de types:  109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvtUCWdZRpR_",
        "outputId": "829c92f6-81b3-4846-bd83-596477b690c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['E', 'agora', ',', 'José', '?', 'A', 'festa', 'acabou', ',', 'a', 'luz', 'apagou', ',', 'o', 'povo', 'sumiu', ',', 'a', 'noite', 'esfriou', ',', 'e', 'agora', ',', 'José', '?', 'e', 'agora', ',', 'você', '?', 'você', 'que', 'é', 'sem', 'nome', ',', 'que', 'zomba', 'dos', 'outros', ',', 'você', 'que', 'faz', 'versos', ',', 'que', 'ama', ',', 'protesta', '?', 'e', 'agora', ',', 'José', '?', 'Está', 'sem', 'mulher', ',', 'está', 'sem', 'discurso', ',', 'está', 'sem', 'carinho', ',', 'já', 'não', 'pode', 'beber', ',', 'já', 'não', 'pode', 'fumar', ',', 'cuspir', 'já', 'não', 'pode', ',', 'a', 'noite', 'esfriou', ',', 'o', 'dia', 'não', 'veio', ',', 'o', 'bonde', 'não', 'veio', ',', 'o', 'riso', 'não', 'veio', ',', 'não', 'veio', 'a', 'utopia', 'e', 'tudo', 'acabou', 'e', 'tudo', 'fugiu', 'e', 'tudo', 'mofou', ',', 'e', 'agora', ',', 'José', '?', 'E', 'agora', ',', 'José', '?', 'Sua', 'doce', 'palavra', ',', 'seu', 'instante', 'de', 'febre', ',', 'sua', 'gula', 'e', 'jejum', ',', 'sua', 'biblioteca', ',', 'sua', 'lavra', 'de', 'ouro', ',', 'seu', 'terno', 'de', 'vidro', ',', 'sua', 'incoerência', ',', 'seu', 'ódio', '-', 'e', 'agora', '?', 'Com', 'a', 'chave', 'na', 'mão', 'quer', 'abrir', 'a', 'porta', ',', 'não', 'existe', 'porta', ';', 'quer', 'morrer', 'no', 'mar', ',', 'mas', 'o', 'mar', 'secou', ';', 'quer', 'ir', 'para', 'Minas', ',', 'Minas', 'não', 'há', 'mais', '.', 'José', ',', 'e', 'agora', '?', 'Se', 'você', 'gritasse', ',', 'se', 'você', 'gemesse', ',', 'se', 'você', 'tocasse', 'a', 'valsa', 'vienense', ',', 'se', 'você', 'dormisse', ',', 'se', 'você', 'cansasse', ',', 'se', 'você', 'morresse', '...', 'Mas', 'você', 'não', 'morre', ',', 'você', 'é', 'duro', ',', 'José', '!', 'Sozinho', 'no', 'escuro', 'qual', 'bicho-do-mato', ',', 'sem', 'teogonia', ',', 'sem', 'parede', 'nua', 'para', 'se', 'encostar', ',', 'sem', 'cavalo', 'preto', 'que', 'fuja', 'a', 'galope', ',', 'você', 'marcha', ',', 'José', '!', 'José', ',', 'para', 'onde', '?']\n",
            "274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulario)\n",
        "print(len(vocabulario))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-sIqnL-Rs9X",
        "outputId": "d8cb47df-07db-401e-d554-1e9283463777"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'encostar', 'dia', 'pode', 'marcha', 'parede', 'mas', 'festa', 'cansasse', 'existe', 'acabou', 'morrer', 'luz', 'se', 'valsa', 'povo', 'febre', 'tocasse', 'nua', 'terno', 'sem', 'gritasse', 'é', 'quer', 'noite', '!', 'utopia', 'esfriou', 'jejum', 'cavalo', 'veio', 'no', 'agora', 'não', 'mar', 'vienense', 'faz', 'duro', 'chave', 'protesta', 'biblioteca', 'doce', 'bonde', 'secou', 'há', 'mais', 'josé', 'galope', 'sua', 'onde', 'palavra', 'cuspir', 'o', 'zomba', 'discurso', 'preto', 'sumiu', 'fumar', 'fugiu', 'com', ';', 'fuja', 'que', 'gemesse', 'e', 'morresse', 'mofou', 'ódio', 'escuro', 'na', 'morre', 'mão', 'a', 'vidro', 'você', 'qual', 'está', 'gula', 'apagou', 'ama', 'já', 'sozinho', '.', 'beber', 'teogonia', 'porta', ',', '...', 'ouro', 'incoerência', 'abrir', 'mulher', '?', 'de', 'dormisse', 'nome', 'versos', 'instante', 'seu', 'outros', 'carinho', 'minas', 'dos', '-', 'bicho-do-mato', 'riso', 'para', 'tudo', 'ir', 'lavra'}\n",
            "109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentação de sentenças"
      ],
      "metadata": {
        "id": "AhhIvRTRR1oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentencas = nltk.sent_tokenize(poema, language=\"portuguese\")\n",
        "print(sentencas)\n",
        "print(len(sentencas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g00STaIFR1L7",
        "outputId": "d8de6018-e044-450e-8c9c-3c2305a991b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['E agora, José?', 'A festa acabou,\\na luz apagou,\\no povo sumiu,\\na noite esfriou,\\ne agora, José?', 'e agora, você?', 'você que é sem nome,\\nque zomba dos outros,\\nvocê que faz versos,\\nque ama, protesta?', 'e agora, José?', 'Está sem mulher,\\nestá sem discurso,\\nestá sem carinho,\\njá não pode beber,\\njá não pode fumar,\\ncuspir já não pode,\\na noite esfriou,\\no dia não veio,\\no bonde não veio,\\no riso não veio,\\nnão veio a utopia\\ne tudo acabou\\ne tudo fugiu\\ne tudo mofou,\\ne agora, José?', 'E agora, José?', 'Sua doce palavra,\\nseu instante de febre,\\nsua gula e jejum,\\nsua biblioteca,\\nsua lavra de ouro,\\nseu terno de vidro,\\nsua incoerência,\\nseu ódio - e agora?', 'Com a chave na mão\\nquer abrir a porta,\\nnão existe porta;\\nquer morrer no mar,\\nmas o mar secou;\\nquer ir para Minas,\\nMinas não há mais.', 'José, e agora?', 'Se você gritasse,\\nse você gemesse,\\nse você tocasse\\na valsa vienense,\\nse você dormisse,\\nse você cansasse,\\nse você morresse...', 'Mas você não morre,\\nvocê é duro, José!', 'Sozinho no escuro\\nqual bicho-do-mato,\\nsem teogonia,\\nsem parede nua\\npara se encostar,\\nsem cavalo preto\\nque fuja a galope,\\nvocê marcha, José!', 'José, para onde?']\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similaridade textual"
      ],
      "metadata": {
        "id": "McyOtSv6DQU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UzzAr9N372mX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = ['Goku is a hero in the Dragon Ball since 1989! Goku saved the earth so many times.',\n",
        "         'The 7 Dragon balls can make wishes come true! Each ball contains his own dragon.',\n",
        "         'If the wishes are superfluous, the dragon balls will become dark.' ,\n",
        "         'Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.',\n",
        "         \"A knight of the zodiac wear a bronze, silver or a gold cloth to protect Athena.\",\n",
        "         'Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.']\n",
        "classes = ['Dragon Ball', 'Dragon Ball', 'Dragon Ball', 'Cav. Zod.', 'Cav. Zod.', 'Cav. Zod.']\n",
        "\n",
        "df = pd.DataFrame({'texts': texts, 'classes': classes})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "lvBveXtE74TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f7c70c-3c86-4d22-d048-dde84cf82eb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similaridade Textual baseada em caracteres"
      ],
      "metadata": {
        "id": "KPzlLxzl6R00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A distância de Levenshtein\n",
        "\n",
        "\"Este método foi inventado em 1965 pelo matemático russo Vladimir Levenshtein (1935-2017). O valor da distância descreve o número mínimo de remoções, inserções ou substituições necessárias para transformar uma *string* em outra.\"\n",
        "\n",
        "FONTE: [Distância de Levenshtein e similaridade de texto em Python](http://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/)"
      ],
      "metadata": {
        "id": "5uRcpUp96ZVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein(seq1, seq2):\n",
        "    # criar uma matriz\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "\n",
        "    # setar número de colunas (0, n-1)\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "\n",
        "    # setar número de linhas (0, n-1)\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    # calcular a distancia\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            # se os caracteres sao iguais, nao aumenta a distancia\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = matrix[x-1, y-1]\n",
        "            # se são diferentes, aumenta a distancia em 1\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "\n",
        "    # imprime a matriz de calculo da distancia\n",
        "    # list(seq1) converte string em uma lista de caracteres\n",
        "    print(pd.DataFrame(matrix[1:,1:], index=list(seq1), columns=list(seq2)))\n",
        "\n",
        "    return (matrix[size_x - 1, size_y - 1])"
      ],
      "metadata": {
        "id": "8L9lF8VC6i0U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "levenshtein('medicina','medico')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ2QkBxiHpiz",
        "outputId": "a9b720b3-3a9d-4d66-ea8d-6be27132ca05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     m    e    d    i    c    o\n",
            "m  0.0  1.0  2.0  3.0  4.0  5.0\n",
            "e  1.0  0.0  1.0  2.0  3.0  4.0\n",
            "d  2.0  1.0  0.0  1.0  2.0  3.0\n",
            "i  3.0  2.0  1.0  0.0  1.0  2.0\n",
            "c  4.0  3.0  2.0  1.0  0.0  1.0\n",
            "i  5.0  4.0  3.0  2.0  1.0  1.0\n",
            "n  6.0  5.0  4.0  3.0  2.0  2.0\n",
            "a  7.0  6.0  5.0  4.0  3.0  3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando a distância de Levenshtein para comparar textos/sentenças\n",
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id_a = 3 # id do texto 1\n",
        "doc_id_b = 2 # id do texto 2\n",
        "print(\"texto 1: \",df.loc[doc_id_a]['texts'])\n",
        "print(\"texto 2: \",df.loc[doc_id_b]['texts'])\n",
        "print (\"------\")\n",
        "\n",
        "levenshtein(df.loc[doc_id_a]['texts'],df.loc[doc_id_b]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRz_I16hHyqW",
        "outputId": "3f81b5d9-b29e-4e7a-dc4d-772d107c9210"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "texto 1:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n",
            "texto 2:  If the wishes are superfluous, the dragon balls will become dark.\n",
            "------\n",
            "        I      f           t     h     e           w     i     s  ...     c  \\\n",
            "S     1.0    2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0  10.0  ...  56.0   \n",
            "e     2.0    2.0   3.0   4.0   5.0   5.0   6.0   7.0   8.0   9.0  ...  55.0   \n",
            "i     3.0    3.0   3.0   4.0   5.0   6.0   6.0   7.0   7.0   8.0  ...  54.0   \n",
            "y     4.0    4.0   4.0   4.0   5.0   6.0   7.0   7.0   8.0   8.0  ...  54.0   \n",
            "a     5.0    5.0   5.0   5.0   5.0   6.0   7.0   8.0   8.0   9.0  ...  53.0   \n",
            "..    ...    ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
            "i    97.0   96.0  95.0  94.0  93.0  92.0  91.0  91.0  90.0  89.0  ...  74.0   \n",
            "m    98.0   97.0  96.0  95.0  94.0  93.0  92.0  92.0  91.0  90.0  ...  75.0   \n",
            "e    99.0   98.0  97.0  96.0  95.0  94.0  93.0  93.0  92.0  91.0  ...  76.0   \n",
            "s   100.0   99.0  98.0  97.0  96.0  95.0  94.0  94.0  93.0  92.0  ...  76.0   \n",
            ".   101.0  100.0  99.0  98.0  97.0  96.0  95.0  95.0  94.0  93.0  ...  77.0   \n",
            "\n",
            "       o     m     e           d     a     r     k     .  \n",
            "S   57.0  58.0  59.0  60.0  61.0  62.0  63.0  64.0  65.0  \n",
            "e   56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  64.0  \n",
            "i   55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  \n",
            "y   55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  63.0  \n",
            "a   54.0  55.0  56.0  57.0  58.0  59.0  60.0  61.0  62.0  \n",
            "..   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
            "i   74.0  74.0  74.0  73.0  73.0  73.0  74.0  75.0  75.0  \n",
            "m   75.0  74.0  75.0  74.0  74.0  74.0  74.0  75.0  76.0  \n",
            "e   76.0  75.0  74.0  75.0  75.0  75.0  75.0  75.0  76.0  \n",
            "s   77.0  76.0  75.0  75.0  76.0  76.0  76.0  76.0  76.0  \n",
            ".   77.0  77.0  76.0  76.0  76.0  77.0  77.0  77.0  76.0  \n",
            "\n",
            "[101 rows x 65 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similaridade Textual baseada em Termos"
      ],
      "metadata": {
        "id": "dDyK54G5K8MP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vetorizando os documentos de treinamento"
      ],
      "metadata": {
        "id": "g9AZrOraTj2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\"\"\"Criando o objeto vetorizador (convertendo para letras minúsculas, removendo as stopwords especificadas em uma lista\n",
        "   e apenas mantendo os termos que ocorreram em dois ou mais documentos\"\"\"\n",
        "vetorizador = CountVectorizer(lowercase=True,\n",
        "                              stop_words=['is', 'are', 'a', 'or', 'to', 'in', 'the', 'so', 'since', 'many', 'of'],\n",
        "                              min_df=2,\n",
        "                              dtype=np.int16\n",
        "                              )"
      ],
      "metadata": {
        "id": "v-9zKxY6776n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo o vocabulário\n",
        "vetorizador.fit(df['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "EnqcxLMT8DZ7",
        "outputId": "80b4d055-f02e-4f57-e1f1-73204acc3ae6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(dtype=<class 'numpy.int16'>, min_df=2,\n",
              "                stop_words=['is', 'are', 'a', 'or', 'to', 'in', 'the', 'so',\n",
              "                            'since', 'many', 'of'])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(dtype=&lt;class &#x27;numpy.int16&#x27;&gt;, min_df=2,\n",
              "                stop_words=[&#x27;is&#x27;, &#x27;are&#x27;, &#x27;a&#x27;, &#x27;or&#x27;, &#x27;to&#x27;, &#x27;in&#x27;, &#x27;the&#x27;, &#x27;so&#x27;,\n",
              "                            &#x27;since&#x27;, &#x27;many&#x27;, &#x27;of&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(dtype=&lt;class &#x27;numpy.int16&#x27;&gt;, min_df=2,\n",
              "                stop_words=[&#x27;is&#x27;, &#x27;are&#x27;, &#x27;a&#x27;, &#x27;or&#x27;, &#x27;to&#x27;, &#x27;in&#x27;, &#x27;the&#x27;, &#x27;so&#x27;,\n",
              "                            &#x27;since&#x27;, &#x27;many&#x27;, &#x27;of&#x27;])</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a representação estruturada a partir do vocabulário ajustado\n",
        "representacao = vetorizador.transform(df['texts'])\n",
        "# A representação retornada é uma matriz em um formato esparso  (posso gerar o array usando toArray())\n",
        "representacao\n",
        "rep_array = representacao.toarray() # a partir daqui podemos aplicar as funções de similaridade\n",
        "print(rep_array)"
      ],
      "metadata": {
        "id": "Ry1DbRvz7IBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7816413-84bd-40a1-9d93-cf52c7ac4d7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 1 0 0 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 1 0 0 0 0 0 1 0]\n",
            " [1 0 0 1 0 1 1 1 1 1 0 1]\n",
            " [1 0 0 1 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosseno"
      ],
      "metadata": {
        "id": "rspLQ4Pq_gwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "matrix_sim = cosine_similarity(rep_array)"
      ],
      "metadata": {
        "id": "4cqsxo4w7J3r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ6CXkxI7Lz8",
        "outputId": "d95f8ba2-ac8c-491b-91f3-2861a591ddfd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.56694671, 0.28867513, 0.35355339, 0.        ,\n",
              "        0.        ],\n",
              "       [0.56694671, 1.        , 0.87287156, 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.28867513, 0.87287156, 1.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.35355339, 0.        , 0.        , 1.        , 0.70710678,\n",
              "        0.61237244],\n",
              "       [0.        , 0.        , 0.        , 0.70710678, 1.        ,\n",
              "        0.28867513],\n",
              "       [0.        , 0.        , 0.        , 0.61237244, 0.28867513,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = cosine_similarity(matrix)\n",
        "  best_sim = -1\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim > best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ],
      "metadata": {
        "id": "mziuF_uC7Niq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "print(\"Texto: \", df.loc[doc_id]['texts'])\n",
        "print(\"Texto mais parecido: \", df.loc[most_similar(doc_id, rep_array)]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm2jWoLd7QJY",
        "outputId": "6a569b7c-0496-4bd4-b6bf-ca17685ce34a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "Texto:  Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.\n",
            "Texto mais parecido:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard"
      ],
      "metadata": {
        "id": "Ro-yzMUODUWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"O índice de Jaccard é uma estatística para comparar e medir a semelhança entre dois conjuntos diferentes. É uma proporção da interseção de dois conjuntos sobre a união deles.\n",
        "\n",
        "Se você tiver um número finito representativo de elementos para uma observação específica e quiser comparar essa observação com outra observação, poderá contar o número de itens comuns a esses dois conjuntos. É um ajuste natural para comparar postagens se você conhece as *tags* representativas das postagens para medir o quão semelhantes dois artigos são em termos de *tags*.\"\n",
        "\n",
        "Fonte: http://bugra.github.io/work/notes/2017-02-07/similarity-via-jaccard-index/"
      ],
      "metadata": {
        "id": "kCDA8pVjT6eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise_distances"
      ],
      "metadata": {
        "id": "DnF85_h3Ao3x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rF93rmYdC-NA"
      },
      "outputs": [],
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = 1 - pairwise_distances(matrix, metric='jaccard') # como é medida de distância (valor entre 0 e 1), utilizar o complemento\n",
        "  best_sim = -1\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim > best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sim = 1 - pairwise_distances(rep_array, metric='jaccard')\n",
        "matrix_sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNuHX7ncC6Sg",
        "outputId": "4acd4b7e-9651-494f-c309-d099e2c19947"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.16666667, 0.2       , 0.        ,\n",
              "        0.        ],\n",
              "       [0.33333333, 1.        , 0.75      , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.16666667, 0.75      , 1.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.2       , 0.        , 0.        , 1.        , 0.5       ,\n",
              "        0.375     ],\n",
              "       [0.        , 0.        , 0.        , 0.5       , 1.        ,\n",
              "        0.16666667],\n",
              "       [0.        , 0.        , 0.        , 0.375     , 0.16666667,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # não imprimir o warning por não utilizar valores binários\n",
        "\n",
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "print(\"Texto: \", df.loc[doc_id]['texts'])\n",
        "print(\"Texto mais parecido: \", df.loc[most_similar(doc_id, rep_array)]['texts'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TsXbLK8A3si",
        "outputId": "f444ddf3-3585-400b-b1b7-888a5d18c8e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n",
            "Texto:  Saint Seiya: Knights of the Zodiac is a Japanese manga in which mystical warriors called the Saints fight wearing sacred cloths.\n",
            "Texto mais parecido:  Seiya is a bronze knight and is one of the main Knights of the Zodiac. He saved Athena several times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard backup (testar depois com os mesmos textos das outras)"
      ],
      "metadata": {
        "id": "Z90YkTuoEV_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(x,y):\n",
        "  \"\"\" retorna a similaridade de jaccard entre duas listas \"\"\"\n",
        "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
        "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
        "  return intersection_cardinality/float(union_cardinality)\n",
        "\n",
        "texto1 = rep_array[5]\n",
        "texto2 = rep_array[3]\n",
        "\n",
        "print(texto1)\n",
        "print(texto2)\n",
        "\n",
        "print(jaccard_similarity(texto1, texto2))\n",
        "\n",
        "print(matrix_sim[5][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNfbXD3EDjtA",
        "outputId": "d1bc7d95-4176-4f15-ff11-8da68ab5210b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 0 1 0 0 1]\n",
            "[1 0 0 1 0 1 1 1 1 1 0 1]\n",
            "1.0\n",
            "0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Euclidiana"
      ],
      "metadata": {
        "id": "_gz4irrEDFjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(id_doc, matrix):\n",
        "  matrix_sim = pairwise_distances(matrix, metric='euclidean')\n",
        "  best_sim = 99999999\n",
        "  id_best_sim = -1;\n",
        "  for id, doc_sim in enumerate(matrix_sim[id_doc]):\n",
        "    if id != id_doc:\n",
        "      if doc_sim <= best_sim:\n",
        "        best_sim = doc_sim\n",
        "        id_best_sim = id\n",
        "  return id_best_sim"
      ],
      "metadata": {
        "id": "87jEthOnEOGr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sim = pairwise_distances(rep_array, metric='euclidean')\n",
        "matrix_sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cSeyivLG-iP",
        "outputId": "aa649190-4799-439e-bfa4-13f5d2a4e872"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 2.23606798, 2.23606798, 2.82842712, 2.82842712,\n",
              "        2.64575131],\n",
              "       [2.23606798, 0.        , 1.41421356, 3.87298335, 3.31662479,\n",
              "        3.16227766],\n",
              "       [2.23606798, 1.41421356, 0.        , 3.31662479, 2.64575131,\n",
              "        2.44948974],\n",
              "       [2.82842712, 3.87298335, 3.31662479, 0.        , 2.        ,\n",
              "        2.23606798],\n",
              "       [2.82842712, 3.31662479, 2.64575131, 2.        , 0.        ,\n",
              "        2.23606798],\n",
              "       [2.64575131, 3.16227766, 2.44948974, 2.23606798, 2.23606798,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "print (\"------\")\n",
        "doc_id = 5\n",
        "#df.loc[doc_id]['texts']\n",
        "df.loc[most_similar(doc_id, rep_array)]['texts']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Lk-XSJrvETEP",
        "outputId": "4949fcc2-4503-45ea-8768-f3d0f95e2cd4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      classes\n",
            "0  Goku is a hero in the Dragon Ball since 1989! ...  Dragon Ball\n",
            "1  The 7 Dragon balls can make wishes come true! ...  Dragon Ball\n",
            "2  If the wishes are superfluous, the dragon ball...  Dragon Ball\n",
            "3  Seiya is a bronze knight and is one of the mai...    Cav. Zod.\n",
            "4  A knight of the zodiac wear a bronze, silver o...    Cav. Zod.\n",
            "5  Saint Seiya: Knights of the Zodiac is a Japane...    Cav. Zod.\n",
            "------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A knight of the zodiac wear a bronze, silver or a gold cloth to protect Athena.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agradecimentos\n",
        "\n",
        "Curso de Tópicos em Inteligência Artificial (Rafael G. Rossi)\n",
        "*   https://github.com/ragero/topicos_inteligencia_artificial_2_2020\n",
        "\n",
        "Similaridade Textual (Alex Sherman)\n",
        "*   https://colab.research.google.com/drive/12x2ygJk2ciN7Wco2_g00MR20jPuMR9_K\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dQWuuu1zdTrr"
      }
    }
  ]
}